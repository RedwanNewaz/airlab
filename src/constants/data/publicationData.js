export const publicationData = [
    {
        id: 1,
        title: 'Yolotag-2024',
        year: 2024,
        link: 'https://arxiv.org/abs/2409.02334',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `@inproceedings{Newaz2024YoloTag,
  title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
  author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
  year={2024},
  booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
}`,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 2,
        title: 'Yolotag - 2024',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2024',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 3,
        title: 'Yolotag - 2024',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2024',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 4,
        title: 'Yolotag - 2023',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2023',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 5,
        title: 'Yolotag - 2022',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2022',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 6,
        title: 'Yolotag - 2023',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2023',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
    {
        id: 7,
        title: 'Yolotag - 2022',
        link: 'https://arxiv.org/abs/2409.02334',
        year: '2022',
        authors: ['Sourav Raxit', 'Simant Singh', 'Abdullah Al Redwan Newaz'],
        journal: 'IEEE RO-MAN',
        bibtex: `
        @inproceedings{Newaz2024YoloTag,
          title={YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers},
          author={Newaz, Abdullah Al Redwan and Raxit, Sourav and Singh, Simant},
          year={2024},
          booktitle={IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}
        }
        `,
        abstract: 'By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics. '
    },
]

export const years = ['2024', '2023', '2022', '2021']